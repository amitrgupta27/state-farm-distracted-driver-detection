{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ddexception","provenance":[{"file_id":"1sC10jR0C_D6mKrYb8WDFjqRtjd0MYqNM","timestamp":1590805834996},{"file_id":"1eTVNAap4dPVOlGF70SqR1kG1rTFPpaYh","timestamp":1590775160830},{"file_id":"1mdbVqsqjuqNrirm_Cj2hrkLS4zmTu86Z","timestamp":1590686604373},{"file_id":"/v2/external/notebooks/pro.ipynb","timestamp":1590261075923}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SKQ4bH7qMGrA"},"source":["# Taking advantage of Colab Pro\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QMMqmdiYMkvi"},"source":["## Faster GPUs\n","\n","With Colab Pro you have priority access to our fastest GPUs. For example, you may get a T4 or P100 GPU at times when most users of standard Colab receive a slower K80 GPU. You can see what GPU you've been assigned at any time by executing the following cell."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"23TOba33L4qf","outputId":"076bf777-a799-4edd-ba7c-93442abdc87c","executionInfo":{"status":"ok","timestamp":1591466336923,"user_tz":420,"elapsed":6597,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Sat Jun  6 17:58:55 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Sa-IrJS1aRVJ"},"source":["In order to use a GPU with your notebook, select the Runtime > Change runtime type menu, and then set the hardware accelerator dropdown to GPU."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"65MSuHKqNeBZ"},"source":["## More memory\n","\n","With Colab Pro you have the option to access high-memory VMs when they are available. To set your notebook preference to use a high-memory runtime, select the Runtime > 'Change runtime type' menu, and then select High-RAM in the Runtime shape dropdown.\n","\n","You can see how much memory you have available at any time by running the following code.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V1G82GuO-tez","outputId":"80ac74c6-1288-4b3c-9804-957e13b9194c","executionInfo":{"status":"ok","timestamp":1591466336924,"user_tz":420,"elapsed":6592,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Your runtime has 27.4 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UKGhC3GK3mKM","colab_type":"code","outputId":"a35b372b-4ff5-4f92-87da-baccc12a4f92","executionInfo":{"status":"ok","timestamp":1591466336925,"user_tz":420,"elapsed":6586,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5wc4NJ7y72cY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BJW8Qi-pPpep"},"source":["## Longer runtimes\n","\n","All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). While Colab Pro subscribers still have limits, these will be roughly twice the limits for non-subscribers."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uLlTRcMM_h0k"},"source":["## Resource limits in Colab Pro\n","\n","Your resources are not unlimited in Colab Pro. To make the most of Colab Pro, please avoid using resources when you don't need them. For example, only use a GPU or high-RAM runtime when required, and close Colab tabs when finished.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mm8FzEidvPs6"},"source":["## Send us feedback!\n","\n","If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro and would be interested in a product with higher usage limits, do let us know.\n","\n","If you encounter errors or other issues with billing (payments) for Colab Pro, please email colab-billing@google.com."]},{"cell_type":"code","metadata":{"id":"PGql69jz76OO","colab_type":"code","outputId":"b0fb4597-f1c8-492b-f0fb-44227fc6c652","executionInfo":{"status":"ok","timestamp":1591466339853,"user_tz":420,"elapsed":9506,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd \n","from skimage import io\n","from skimage import color\n","from PIL import Image\n","import PIL.Image\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from dask.array.image import imread\n","from dask import bag, threaded\n","from dask.diagnostics import ProgressBar\n","import cv2\n","from sklearn.model_selection import train_test_split\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","from keras import backend as K\n","from keras.layers.core import Dense, Activation\n","from keras.optimizers import Adam\n","from keras.metrics import categorical_crossentropy\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import imagenet_utils\n","from keras.layers import Dense,GlobalAveragePooling2D\n","from keras.applications import MobileNet\n","from keras.applications.mobilenet import preprocess_input\n","from IPython.display import Image\n","\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten,Input\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.utils import to_categorical\n","from keras.preprocessing import image \n","from keras.layers.normalization import BatchNormalization\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.models import Model\n","from keras import optimizers\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n","Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"43BM1ruo34o-","colab_type":"code","outputId":"c247f9d0-9229-4684-ce20-31fe3e529158","executionInfo":{"status":"ok","timestamp":1591466392465,"user_tz":420,"elapsed":62110,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["import pickle\n","train_image = []\n","image_label = []\n","\n","for i in range(10):\n","  #path = \"/content/drive/My Drive/kaggle/cache/train_r_224_c_224_c_3_class\" + str(i) + \".dat\"\n","  #path = \"/content/drive/My Drive/distdrv/cache/mask_r_224_c_224_c_3_class\" + str(i) + \".dat\"\n","  path = \"/content/drive/My Drive/distdrv/cache/zoommask_r_224_c_224_c_3_class\" + str(i) + \".dat\"\n","\n","  \n","  print(f'loading pickle files from class = {i}')\n","  # get orig image\n","  file = open(path, 'rb')\n","  images, labels = pickle.load(file)\n","  train_image = train_image + images\n","  #image_label = image_label + labels\n","\n","\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["loading pickle files from class = 0\n","loading pickle files from class = 1\n","loading pickle files from class = 2\n","loading pickle files from class = 3\n","loading pickle files from class = 4\n","loading pickle files from class = 5\n","loading pickle files from class = 6\n","loading pickle files from class = 7\n","loading pickle files from class = 8\n","loading pickle files from class = 9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bgYRGVy-aKMQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcPurrMWdmu5","colab_type":"code","colab":{}},"source":["images = []\n","labels = []\n","driver_details = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rD1Np8DsHDMs","colab_type":"code","outputId":"a0e66523-0b17-4ca8-b875-ac17dc71465a","executionInfo":{"status":"ok","timestamp":1591466392467,"user_tz":420,"elapsed":62101,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f'train image size = {len(train_image)}')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["train image size = 22424\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MucET-NhGpWZ","colab_type":"code","colab":{}},"source":["import random\n","\n","random.shuffle(train_image)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUu3RZkbHTcK","colab_type":"code","outputId":"8004dedb-679e-4bc7-e821-b8d549f0ba40","executionInfo":{"status":"ok","timestamp":1591466392469,"user_tz":420,"elapsed":62095,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f'train image size = {len(train_image)}')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["train image size = 22424\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RaukJuGdGpZV","colab_type":"code","colab":{}},"source":["## getting list of driver names\n","\n","D = []\n","for features,labels,drivers in train_image:\n","    D.append(drivers)\n","\n","## Deduplicating drivers\n","\n","deduped = []\n","\n","for i in D:\n","    if i not in deduped:\n","        deduped.append(i)\n","    \n","\n","## selecting random drivers for the validation set\n","driv_selected = []\n","import random\n","driv_nums = random.sample(range(len(deduped)), 4)\n","for i in driv_nums:\n","    driv_selected.append(deduped[i])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0XqfkFLC5OZS","colab_type":"code","outputId":"3bd8822d-ad22-451f-d90d-be05a23fcceb","executionInfo":{"status":"ok","timestamp":1591466392471,"user_tz":420,"elapsed":62088,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["driv_nums"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[17, 22, 14, 21]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"ISh4tQe_5WEq","colab_type":"code","outputId":"43027bc9-152b-4755-e653-91de24bfd166","executionInfo":{"status":"ok","timestamp":1591466392472,"user_tz":420,"elapsed":62083,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(deduped)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"C3cbLpQO5cBn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoFH20RCGpcx","colab_type":"code","outputId":"57b9aa65-6d0f-4a9f-da3b-501a9bcfe8f4","executionInfo":{"status":"ok","timestamp":1591466392473,"user_tz":420,"elapsed":62076,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["## Splitting the train and test\n","\n","X_train= []\n","y_train = []\n","X_test = []\n","y_test = []\n","D_train = []\n","D_test = []\n","\n","#for features,labels,drivers,features2,labels2,drivers2 in zip(train_image, train_image2):\n","for features, labels, drivers in train_image:\n","\n","    if drivers in driv_selected:\n","        X_test.append(features)\n","        y_test.append(labels)\n","        #D_test.append(drivers)\n","    \n","    else:\n","        X_train.append(features)\n","        y_train.append(labels)\n","        #D_train.append(drivers)\n","\n","\n","true_test = y_test\n","    \n","print (len(X_train),len(X_test))\n","print (len(y_train),len(y_test))\n","\n","\n","\n","\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["19357 3067\n","19357 3067\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nHbHOJQwx3gY","colab_type":"code","outputId":"4779ae6f-8a74-45e9-9be4-937c8e2dc7fd","executionInfo":{"status":"ok","timestamp":1591466394052,"user_tz":420,"elapsed":63650,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(X_train)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19357"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Jlp7ToMJGpfj","colab_type":"code","outputId":"5490a7ca-6e85-417f-b520-d97013942214","executionInfo":{"status":"ok","timestamp":1591466398321,"user_tz":420,"elapsed":67913,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["## Converting images to nparray. Encoding the Y\n","\n","X_train = np.array(X_train).reshape(-1,224,224,3)\n","X_test = np.array(X_test).reshape(-1,224,224,3)\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","print (X_train.shape)\n","print (X_test.shape)\n","print (y_train.shape)\n","print (y_test.shape)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(19357, 224, 224, 3)\n","(3067, 224, 224, 3)\n","(19357, 10)\n","(3067, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"12dMipCGN5cs","colab_type":"code","colab":{}},"source":["from __future__ import print_function  # for Python2\n","import sys\n","\n","local_vars = list(locals().items())\n","for var, obj in local_vars:\n","  #print(var, sys.getsizeof(obj))\n","  pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dNH_HZilPaM","colab_type":"code","outputId":"dd950be1-6369-4860-ccaf-53c5969df1e4","executionInfo":{"status":"ok","timestamp":1591466413638,"user_tz":420,"elapsed":83222,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## Defining the input\n","from keras.layers import Input\n","xception_input = Input(shape = (224, 224, 3), name = 'Image_input')\n","\n","## The RESNET model\n","\n","from keras.applications.xception import preprocess_input, decode_predictions\n","from keras.applications.xception import Xception\n","\n","\n","#Get the RESNET weights and layers\n","\n","model_xception_conv = Xception(weights= 'imagenet', include_top=False, input_shape= (224,224,3))\n","model_xception_conv.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 2s 0us/step\n","Model: \"xception\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 55, 55, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_3[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_4[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_5[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_6[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_7[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_8[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_9[0][0]                      \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_10[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n","==================================================================================================\n","Total params: 20,861,480\n","Trainable params: 20,806,952\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iY7CAPT7GpiC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_lBw1i1Xk34T","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJf-DE7DdURw","colab_type":"code","outputId":"0ffa9b80-dc71-4883-882f-61b4abfcc754","executionInfo":{"status":"ok","timestamp":1591466415845,"user_tz":420,"elapsed":85419,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["#Use the generated model \n","from keras.models import Model\n","\n","\n","output_xception_conv = model_xception_conv(xception_input)\n","\n","#Add the fully-connected layers \n","\n","x=GlobalAveragePooling2D()(output_xception_conv)\n","x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n","x = Dropout(0.1)(x) # **reduce dropout \n","x=Dense(1024,activation='relu')(x) #dense layer 2\n","x = BatchNormalization()(x)\n","x = Dropout(0.35)(x)\n","x = Dense(512,activation='relu')(x) #dense layer 3\n","x = Dense(10, activation='softmax', name='predictions')(x)\n","\n","\n","xception_pretrained = Model(input = xception_input, output = x)\n","# for layer in resnet50_pretrained.layers[:2]:\n","#     layer.trainable=False\n","# for layer in resnet50_pretrained.layers[2:]:\n","#     layer.trainable=True\n","\n","\n","xception_pretrained.summary()\n","\n","\n","# Compile CNN model\n","adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0)\n","sgd = optimizers.SGD(lr = 0.005)\n","xception_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Image_input (InputLayer)     (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","xception (Model)             (None, 7, 7, 2048)        20861480  \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","predictions (Dense)          (None, 10)                5130      \n","=================================================================\n","Total params: 24,543,282\n","Trainable params: 24,486,706\n","Non-trainable params: 56,576\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KHlcK4zQdXgo","colab_type":"code","outputId":"12de8a2b-f2b7-4b90-ba0c-be4ae9cc3db1","executionInfo":{"status":"ok","timestamp":1591473988889,"user_tz":420,"elapsed":7658456,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","\n","checkpointer = ModelCheckpoint('/content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5', verbose=1, save_best_only=True)\n","earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n","\n","\n","datagen = ImageDataGenerator(\n","    height_shift_range=0.5,\n","    width_shift_range = 0.5,\n","    zoom_range = 0.5,\n","    rotation_range=30\n","        )\n","#datagen.fit(X_train)\n","data_generator = datagen.flow(X_train, y_train, batch_size = 64)\n","\n","# Fits the model on batches with real-time data augmentation:\n","xception_model = xception_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper],\n","                                                            epochs = 30, verbose = 1, validation_data = (X_test, y_test))\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","303/302 [==============================] - 344s 1s/step - loss: 2.3027 - accuracy: 0.1741 - val_loss: 2.2231 - val_accuracy: 0.2938\n","\n","Epoch 00001: val_loss improved from inf to 2.22307, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 2/30\n","303/302 [==============================] - 327s 1s/step - loss: 1.8078 - accuracy: 0.3636 - val_loss: 1.3755 - val_accuracy: 0.5634\n","\n","Epoch 00002: val_loss improved from 2.22307 to 1.37551, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 3/30\n","303/302 [==============================] - 327s 1s/step - loss: 1.3043 - accuracy: 0.5464 - val_loss: 0.8363 - val_accuracy: 0.7069\n","\n","Epoch 00003: val_loss improved from 1.37551 to 0.83634, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 4/30\n","303/302 [==============================] - 326s 1s/step - loss: 1.0269 - accuracy: 0.6453 - val_loss: 0.7017 - val_accuracy: 0.7551\n","\n","Epoch 00004: val_loss improved from 0.83634 to 0.70169, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 5/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.8645 - accuracy: 0.7004 - val_loss: 0.5668 - val_accuracy: 0.7995\n","\n","Epoch 00005: val_loss improved from 0.70169 to 0.56682, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 6/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.7794 - accuracy: 0.7337 - val_loss: 0.5423 - val_accuracy: 0.8089\n","\n","Epoch 00006: val_loss improved from 0.56682 to 0.54234, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 7/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.7010 - accuracy: 0.7578 - val_loss: 0.5074 - val_accuracy: 0.8285\n","\n","Epoch 00007: val_loss improved from 0.54234 to 0.50740, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 8/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.6632 - accuracy: 0.7712 - val_loss: 0.5361 - val_accuracy: 0.8243\n","\n","Epoch 00008: val_loss did not improve from 0.50740\n","Epoch 9/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.5955 - accuracy: 0.7927 - val_loss: 0.5045 - val_accuracy: 0.8334\n","\n","Epoch 00009: val_loss improved from 0.50740 to 0.50450, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 10/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.5698 - accuracy: 0.8029 - val_loss: 0.4993 - val_accuracy: 0.8350\n","\n","Epoch 00010: val_loss improved from 0.50450 to 0.49928, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 11/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.5488 - accuracy: 0.8113 - val_loss: 0.4616 - val_accuracy: 0.8497\n","\n","Epoch 00011: val_loss improved from 0.49928 to 0.46157, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 12/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.5160 - accuracy: 0.8194 - val_loss: 0.4847 - val_accuracy: 0.8432\n","\n","Epoch 00012: val_loss did not improve from 0.46157\n","Epoch 13/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.5015 - accuracy: 0.8276 - val_loss: 0.4472 - val_accuracy: 0.8474\n","\n","Epoch 00013: val_loss improved from 0.46157 to 0.44723, saving model to /content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5\n","Epoch 14/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.4802 - accuracy: 0.8329 - val_loss: 0.4578 - val_accuracy: 0.8448\n","\n","Epoch 00014: val_loss did not improve from 0.44723\n","Epoch 15/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.4568 - accuracy: 0.8434 - val_loss: 0.4833 - val_accuracy: 0.8481\n","\n","Epoch 00015: val_loss did not improve from 0.44723\n","Epoch 16/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.4329 - accuracy: 0.8503 - val_loss: 0.5004 - val_accuracy: 0.8350\n","\n","Epoch 00016: val_loss did not improve from 0.44723\n","Epoch 17/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.4267 - accuracy: 0.8527 - val_loss: 0.4508 - val_accuracy: 0.8621\n","\n","Epoch 00017: val_loss did not improve from 0.44723\n","Epoch 18/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.4107 - accuracy: 0.8573 - val_loss: 0.5364 - val_accuracy: 0.8353\n","\n","Epoch 00018: val_loss did not improve from 0.44723\n","Epoch 19/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.3941 - accuracy: 0.8641 - val_loss: 0.5432 - val_accuracy: 0.8389\n","\n","Epoch 00019: val_loss did not improve from 0.44723\n","Epoch 20/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.3908 - accuracy: 0.8661 - val_loss: 0.4733 - val_accuracy: 0.8559\n","\n","Epoch 00020: val_loss did not improve from 0.44723\n","Epoch 21/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.3781 - accuracy: 0.8683 - val_loss: 0.4975 - val_accuracy: 0.8523\n","\n","Epoch 00021: val_loss did not improve from 0.44723\n","Epoch 22/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.3669 - accuracy: 0.8720 - val_loss: 0.4868 - val_accuracy: 0.8562\n","\n","Epoch 00022: val_loss did not improve from 0.44723\n","Epoch 23/30\n","303/302 [==============================] - 326s 1s/step - loss: 0.3556 - accuracy: 0.8783 - val_loss: 0.4504 - val_accuracy: 0.8591\n","\n","Epoch 00023: val_loss did not improve from 0.44723\n","Epoch 00023: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xd5H2X5tGnED","colab_type":"code","colab":{}},"source":["#vgg16_model.save(\"/content/drive/My Drive/kaggle/singleModel_aug.h5\")\n","xception_pretrained.save_weights(\"/content/drive/My Drive/kaggle/xceptionmaskModel_aug_weights.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SklAZD_fT0Hy","colab_type":"code","outputId":"6af3cd41-d7d3-4571-9a53-3200c731efd6","executionInfo":{"status":"ok","timestamp":1591474224815,"user_tz":420,"elapsed":20327,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":493}},"source":["from keras.models import load_model\n","rcModel = load_model('/content/drive/My Drive/kaggle/xceptionmaskModel_aug.hdf5')\n","rcModel.summary()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Image_input (InputLayer)     (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","xception (Model)             (None, 7, 7, 2048)        20861480  \n","_________________________________________________________________\n","global_average_pooling2d_1 ( (None, 2048)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","predictions (Dense)          (None, 10)                5130      \n","=================================================================\n","Total params: 24,543,282\n","Trainable params: 24,486,706\n","Non-trainable params: 56,576\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1zyAbBXXWti4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6a680147-bf2a-4338-ebea-e87c1111321a","executionInfo":{"status":"ok","timestamp":1591474225225,"user_tz":420,"elapsed":402,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}}},"source":["X_test.shape"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3067, 224, 224, 3)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"E4UBzXvyTnt-","colab_type":"code","outputId":"92fc6ce6-17f4-4d37-b0f0-377b07a06600","executionInfo":{"status":"ok","timestamp":1591474239015,"user_tz":420,"elapsed":14183,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["# labels is the image array\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","model1_prediction = []\n","model1_pred_class = []\n","\n","model1_prediction = rcModel.predict(X_test)\n","print('Images Predicted until now:',len(model1_prediction))\n","print(f'True images: {len(true_test)}')\n","\n","for i in range(len(model1_prediction)):\n","    model1_pred_class.append(np.where(model1_prediction[i] == np.amax(model1_prediction[i]))[0][0])\n","\n","    \n","print('The accuracy of this model over validation set is:',accuracy_score(true_test,model1_pred_class))\n","confusion_matrix(true_test,model1_pred_class)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Images Predicted until now: 3067\n","True images: 3067\n","The accuracy of this model over validation set is: 0.8474078904466906\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[205,   1,   0,   0,   1,  21,   1,   0,  17,  43],\n","       [  7, 267,   0,   0,   0,   0,   4,   2,   1,   7],\n","       [  0,   0, 268,   0,   0,   0,   6,   0,  60,   0],\n","       [  1,   2,   0, 292,   4,   1,   1,   0,  11,   1],\n","       [  1,   0,   1,   3, 294,   0,   1,   0,  17,   1],\n","       [  3,   0,   0,   0,   0, 315,   0,   0,   0,   0],\n","       [  0,  21,   0,   0,   0,   0, 298,   0,   4,   0],\n","       [  0,   0,   0,   0,   0,   1,   0, 277,   1,   0],\n","       [  7,   0,   4,   0,   1,   1,  67,   5, 200,   2],\n","       [ 68,   1,   0,   1,   1,  26,   0,  34,   4, 183]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"P2PQ1gIhXXIO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"outputId":"08a33a0c-a7e2-41b1-9238-4d1126c6b178","executionInfo":{"status":"ok","timestamp":1591474039175,"user_tz":420,"elapsed":7708724,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}}},"source":["print(f'prediction={model1_prediction}, shape={model1_prediction.shape}')"],"execution_count":25,"outputs":[{"output_type":"stream","text":["prediction=[[7.8515772e-04 9.9393433e-01 4.3523800e-05 ... 3.6568981e-05\n","  4.9636350e-04 2.0862906e-03]\n"," [1.3213544e-04 2.7401693e-04 4.6475622e-04 ... 2.3031757e-04\n","  2.2209704e-02 3.3677058e-04]\n"," [4.2811334e-06 4.1560465e-06 9.8986560e-01 ... 2.9833677e-06\n","  9.4424039e-03 1.9848729e-05]\n"," ...\n"," [8.9626810e-05 3.2739728e-04 6.2108855e-04 ... 3.9202248e-04\n","  2.0481825e-03 7.7055156e-04]\n"," [2.0210673e-04 1.2613500e-03 2.5991503e-05 ... 1.1297927e-03\n","  2.4344025e-02 2.9230684e-03]\n"," [4.3133627e-05 2.3499433e-05 4.2250651e-01 ... 5.7906494e-04\n","  5.2107799e-01 4.2932166e-04]], shape=(3067, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yP06M7AwXrVO","colab_type":"code","outputId":"3a827582-b5b5-46c4-93fc-ed4c26543ea9","executionInfo":{"status":"ok","timestamp":1591474243850,"user_tz":420,"elapsed":352,"user":{"displayName":"Amit Gupta","photoUrl":"","userId":"05965806125720489979"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import log_loss\n","\n","lgloss = log_loss(y_test, model1_prediction, eps=1e-15, normalize=True, sample_weight=None, labels=None)\n","\n","print('The log loss from this model is:',round(lgloss,2))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["The log loss from this model is: 0.45\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u5jlqhDY2rJQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAZ-Lj8n2r4C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}